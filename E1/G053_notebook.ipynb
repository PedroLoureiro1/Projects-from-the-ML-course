{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports - Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dados dos ficheiros auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data, _ = arff.loadarff('diabetes.arff')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', \n",
    "              'BMI', 'DiabetesPedigreeFunction', 'Age', 'Class']\n",
    "df['Class'] = df['Class'].astype(int)\n",
    "\n",
    "X, y = df.drop('Class', axis=1), df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aplicar ANOVA para identificar os valores F e p\n",
    "F_values, p_values = f_classif(X, y)\n",
    "\n",
    "# Criar um DataFrame para armazenar os resultados do ANOVA\n",
    "anova_results = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F-value': F_values,\n",
    "    'p-value': p_values\n",
    "})\n",
    "\n",
    "# Ordenar as variáveis de acordo com o F-value (da maior para a menor)\n",
    "anova_results_sorted = anova_results.sort_values(by='F-value', ascending=False)\n",
    "\n",
    "# 3. Identificar as variáveis com melhor e pior poder discriminativo\n",
    "best_feature = anova_results_sorted['Feature'].iloc[0]\n",
    "worst_feature = anova_results_sorted['Feature'].iloc[-1]\n",
    "\n",
    "print(f\"\\nMelhor variável discriminativa: {best_feature}\")\n",
    "print(f\"Pior variável discriminativa: {worst_feature}\")\n",
    "\n",
    "# 4. Função para plotar a densidade de probabilidade condicional por classe\n",
    "def plot_density_by_class(X, y, feature, feature_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_label in np.unique(y):\n",
    "        subset = X[y == class_label]\n",
    "        label = \"Normal\" if class_label == 0 else \"Diabetes\"\n",
    "        sns.kdeplot(subset[feature], label=f\"{label}\", fill=True)\n",
    "    plt.title(f\"Densidade Condicional para {feature_name}\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Densidade')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 5. Plotar a densidade da variável com o melhor poder discriminativo\n",
    "plot_density_by_class(X, y, best_feature, f\"{best_feature}\")\n",
    "\n",
    "# Plotar a densidade da variável com o pior poder discriminativo\n",
    "plot_density_by_class(X, y, worst_feature, f\"{worst_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target labels to numeric if necessary\n",
    "#y = y.map({'tested_negative': 0, 'tested_positive': 1})\n",
    "\n",
    "# Stratified 80-20 split with a fixed seed (random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
    "\n",
    "# Range of min_samples_split values to test\n",
    "min_samples_split_values = [2, 5, 10, 20, 30, 50, 100]\n",
    "\n",
    "# Store accuracies for each value of min_samples_split\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through different values of min_samples_split\n",
    "for min_samples_split in min_samples_split_values:\n",
    "    # Create a decision tree classifier with the current min_samples_split\n",
    "    clf = DecisionTreeClassifier(min_samples_split=min_samples_split, random_state=1)\n",
    "    \n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "# Plot the training and testing accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(min_samples_split_values, train_accuracies, label='Training Accuracy', marker='o', linestyle='--', color='blue')\n",
    "plt.plot(min_samples_split_values, test_accuracies, label='Testing Accuracy', marker='o', linestyle='-', color='green')\n",
    "plt.title('Training and Testing Accuracies for Different min_samples_split Values')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_tree_accuracies.png')  # Save the plot as an image\n",
    "plt.show()  # Display the plot\n",
    "plt.close()  # Close the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, iremos analisar a acurácia nos dados de treino.\n",
    "A acurácia nestes dados começa extremamente alta (~1.0) quando o valor de min_samples_split é muito baixo.\n",
    "À medida que o valor de min_samples_split aumenta, a acurácia de treino diminui gradualmente.\n",
    "Este fenómeno ocorre visto que um valor baixo de min_samples_split permite que a árvore seja muito complexa, resultando em overfitting. Com um min_samples_split maior, a árvore é forçada a generalizar melhor, levando a uma menor acurácia no treino.\n",
    "\n",
    "Em segundo lugar, iremos analisar a acurácia nos dados de teste.\n",
    "Inicialmente, a acurácia de teste é baixa (~0.70), mas melhora conforme o valor de min_samples_split aumenta até cerca de 30.\n",
    "A acurácia de teste atinge um pico em torno de min_samples_split = 50, indicando o ponto de melhor generalização do modelo.\n",
    "Após esse ponto, a acurácia de teste diminui lentamente, sugerindo que um aumento maior no parâmetro simplifica em demasia o modelo, reduzindo a sua capacidade de capturar as relações nos dados.\n",
    "\n",
    "Em suma, conseguimos observar que para valores muito baixos, o modelo é altamente complexo e sofre de overfitting, o que indica uma baixa capacidade de generalização. Em contrapartida, para valores muito altos de min_samples_split, o modelo revela-se muito simples e não consegue capturar adequadamente a estrutura dos dados, resultando em underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target labels to numeric\n",
    "#y = y.map({'tested_negative': 0, 'tested_positive': 1})\n",
    "\n",
    "# Train a Decision Tree with max_depth=3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(clf, feature_names=X.columns, class_names=['Normal', 'Diabetes'], filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree (max_depth=3)\")\n",
    "plt.savefig('decision_tree_depth3.png')  # Save the plot as an image\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glucose > 127.5\n",
    "\n",
    "O primeiro nível de divisão da árvore é baseado nos níveis de glucose. Se a glucose for superior a 127.5, há uma elevada probabilidade de a pessoa ter diabetes.\n",
    "Após esta divisão, o ramo à direita contém 283 amostras, das quais 174 são classificadas como diabetes (61,5%).\n",
    "\n",
    "BMI ≤ 29.95 (dado Glucose > 127.5):\n",
    "\n",
    "Entre os indivíduos com glucose > 127.5, se o BMI for menor ou igual a 29.95, a probabilidade de terem diabetes é alta.\n",
    "Este ramo tem 283 amostras, com 109 classificadas como normais e 174 como diabetes (Gini = 0.474).\n",
    "\n",
    "Glucose > 157.5 (dado Glucose > 127.5 e BMI > 29.95):\n",
    "\n",
    "Se o BMI for superior a 29.95 e a glucose for maior que 157.5, a probabilidade de diabetes aumenta ainda mais.\n",
    "Nesta divisão, há 207 amostras, com 150 indivíduos classificados como diabetes (72,5%)\n",
    "\n",
    "Glucose ≤ 157.5 e BMI > 29.95:\n",
    "\n",
    "Mesmo quando a glucose está elevada (mas ≤ 157.5) e o BMI também está acima de 29.95, há ainda uma elevada probabilidade de diabetes.\n",
    "Neste caso, há 92 amostras, com 80 indivíduos classificados como diabetes (87%).\n",
    "\n",
    "Os principais fatores que indicam diabetes são níveis elevados de glucose (especialmente superiores a 127.5) e BMI superior a 29.95. Níveis elevados de glucose, particularmente acima de 157.5, combinados com um BMI elevado, aumentam a probabilidade de diabetes para mais de 70-80%. Níveis baixos de glucose (≤ 127.5) estão mais associados à classe \"normal\", o que indica que a glucose é o principal preditor neste modelo.\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "Glucose ≤ 127.5 e Idade ≤ 28.5:\n",
    "\n",
    "Neste ramo, estamos a falar de pessoas com glucose relativamente baixa (≤ 127.5) e idade jovem (≤ 28.5).\n",
    "Este grupo tem 485 amostras no total, das quais apenas 94 são classificadas como diabetes (19,4% de probabilidade de diabetes), ou seja, a maioria é classificada como normal.\n",
    "Idade ≤ 28.5 e BMI ≤ 45.4:\n",
    "\n",
    "Se a pessoa tem menos de 28.5 anos e um BMI ≤ 45.4, a probabilidade de ser normal é muito alta. Das 271 amostras, 248 são classificadas como normais (Gini = 0.155), o que mostra uma probabilidade bastante reduzida de ter diabetes.\n",
    "Idade ≤ 28.5 e BMI > 45.4:\n",
    "\n",
    "Para as pessoas mais jovens (≤ 28.5 anos) com BMI muito elevado (superior a 45.4), a chance de diabetes aumenta, mas este grupo tem apenas 4 amostras, e dessas, 3 são classificadas como diabetes. Este é um subgrupo muito pequeno, por isso, a conclusão não é tão forte aqui.\n",
    "Idade > 28.5:\n",
    "\n",
    "Quando a idade é superior a 28.5, o próximo critério é o BMI. Aqui, se o BMI for ≤ 26.35, as pessoas têm uma probabilidade elevada de serem normais (143 normais de um total de 214).\n",
    "Se o BMI for maior que 26.35, existe uma maior probabilidade de diabetes (71 amostras de um total de 214).\n",
    "\n",
    "\n",
    "O ramo da idade ajuda a identificar quando uma pessoa provavelmente não tem diabetes, especialmente se for jovem (≤ 28.5 anos) e tiver níveis baixos de glucose (≤ 127.5). A árvore indica que pessoas mais jovens, com baixo nível de glucose, têm uma probabilidade muito reduzida de diabetes. Já a idade, por si só, não parece ser um forte indicador de diabetes, mas sim um fator adicional que, quando combinado com outras características como glucose e BMI, contribui para a previsão.\n",
    "\n",
    "Portanto, o ramo da idade é importante para classificar pessoas como normais, mas, no que diz respeito a identificar diabetes, os fatores mais críticos continuam a ser glucose e BMI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
